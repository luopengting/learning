# 花书概念

## 第8章 深度模型中的优化

- 风险 risk 169
- 代理损失函数 surrogate loss function 170,178
- 确定性 deterministic 171
- 在线 online 171
- 小批量随机 minibatch stochastic 171
- 随机 stochastic 171
- 在线学习 online learning 172,181
- 阶方法 second- order method 172,177,190,251
- 流 stream 172
- 极小值 minima 174-177,179
- 模型可辨识性 model identifiability 174,175
- 局部极小值 local minima 174-176,179,200,323
- 极大值 maxima 175-177
- 权重空间对称性 weight space symmetry 175
- 可辨认的 identifiable 175
- 全局极小值 global minima 176,177,200
- 无鞍牛顿法 saddle-free Newton method 177
- 最陡下降 steepest descent 177
- 梯度爆炸 exploding gradient 177
- 幂方法 power method 178
- 对比散度 contrastive divergence 178,313,370-375,377,403,408,415,416,419,435
- 梯度消失与爆炸问题 vanishing and exploding gradient problem 178,186
- 梯度消失 vanishing gradient 178
- 局部下降 local descent 179,199
- 动量 momentum 181-184,187-190,199,251,258,409
- 额外误差 exces 181,184
- 病态 illconditioning 182
- 微分方程 differential equation 183
- Nesterov动量 Nesterov momentum 183,184,188,189,251
- 混沌 chaos 185
- 稀疏初始化 sparse initialization 186,247
- 随机搜索 random search 186,263,264
- Adagrad Adagrad 187
- 共轭方向 conjugate directions 191
- 共轭梯度 conjugate gradient 191-194
- 共轭 conjugate 192
- 因子图 factor graph 192,493
- BFGS BFGS 193
- 非线性共轭梯度 nonlinear conjugate gradients 193
- Krylov方法 Krylov method 193
- L-BFGS L-BFGS  194,269
- 深度模型 deep model 194
- 块坐标下降 block coordinate descent 196
- 稀疏编码 sparse coding 196,216,225,301-303,308,314,219,322,350,351,354,357,377,385,387-394,398,416,417,422
- 坐标下降 coordinate descent 196
- 贪心监督预训练 greedy supervised pretraining 197
- 贪心算法 greedy algorithm 197,322
- 预训练 pretraining 197-199,221,278,279,303,310,314,317,321-326
- 精调 fne- tuning 197,198
- 延拓法 continuation method 199,200
- 课程学习 curriculum learning 199,200,233
- 随机课程 stochastic curriculum 200
- 塑造 shaping 200,324,400,437
- 神经语言模型 Neural Language Model 200,281,283-287,289,293,334
